{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "215c2eee",
   "metadata": {},
   "source": [
    "# Trabajo Práctico 2: Predicción de precios de propiedades usando modelos de ML de regresón Lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f18ff25",
   "metadata": {},
   "source": [
    " ### Table of Contents\n",
    "\n",
    "* [Objetivos del trabajo 1](#Objetivos) \n",
    "    * [Estratégia 1.1](#Estratégia_1_1)\n",
    "    * [Dataframes y modelos 1.2](#Exploracion_datasets_modeltos_1_2)\n",
    "        * [Dataframes 1.2.1](#Datasets_1_2_1)\n",
    "        * [Modelos 1.2.2](#Modelos_1_2_2)\n",
    "* [Ejecucion de Modelos 2](#chapter2)\n",
    "    * [Modelo 1 2.1](#section_2_1)\n",
    "    * [Section 2.2](#section_2_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4c327d",
   "metadata": {},
   "source": [
    "### Objetivos del Trabajo 1 <a class=\"anchor\" id=\"Objetivos\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21781012",
   "metadata": {},
   "source": [
    "##### El objetivo del trabajo es entrenar y ajustar un modelo de Machine Learning para predecir el precio de propiedades a la venta en Argentina"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3a03f8",
   "metadata": {},
   "source": [
    "\n",
    "#### Estratégia 1.1 <a class=\"anchor\" id=\"estrategia_1_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332d6b50",
   "metadata": {},
   "source": [
    "##### Se definieron las variables más relevantes para el precio de una propiedad en la Argentina Barrio, y tipo de propiedad. En seguida algunas amenities que son muy relevantes en el precio como garage y superficie descubirerta, también son creadas como variables dummmies. Se investigaron amenities que son indicadores de propiedades mas caras y caracteristicas que son indicadores de propiedades mas baratas que también serán pasadas al modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7141bb15",
   "metadata": {},
   "source": [
    "#### Dataframes y Modelos 1.2 <a class=\"anchor\" id=\"section_1_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5134f04",
   "metadata": {},
   "source": [
    "##### Creamos un nuevo dataframe con las variables de interes filtradas y lo salvamos como archivo para levantarlo en esta notebook para alivianar el peso y tiempo de procesamento. A partir del nuevo dataset ajustado con las variables tipo de propiedad, barrio, preciodolar, m2 promedio, amenities, cochera, metros descupbiertos y amenities premium e caracteristicas que restan (colocar bien los nombres aqui). Hacemos selecciones de variables o segmentamos para entrenar y comparar los modelos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f982b5",
   "metadata": {},
   "source": [
    "##### Los modelos que se probarán son Regresión lineal de multiples variables y Regresión lineal de multiples variables con normalización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08516edc",
   "metadata": {},
   "source": [
    "#### Dataframes 1.2.1 <a class=\"anchor\" id=\"Datasets_1_2_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87e9771",
   "metadata": {},
   "source": [
    "##### Los dataframes que construiremos son:\n",
    "##### a. dfA: Agrupacion por barrio, tipo de propiedad dummmie, garage, superficie descubierta, amenities, amenities premium, caracteristicas que restan. Target precio dolar\n",
    "##### b. dfB: Agrupados por regiones (captial federal, GranBA, capitalesInterior, zonaRural) tipo de propiedad dummmie,garage, superficie descubierta, amenities, amenities premium, caracteristicas que re\n",
    "##### c. dfC: Agrupacion por barrio, tipo de propiedad dummmie, garage, superficie descubierta, amenities, amenities premium, caracteristicas que restan. Target precio dolar promedio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50778946",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1224044149.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/m_/52x9bvz90tg_46_xymfkf06m0000gn/T/ipykernel_16313/1224044149.py\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    Import sklearn as sk\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "Import sklearn as sk\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f77cbb",
   "metadata": {},
   "source": [
    "#### Análisis del dfA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9082a703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aqui presentamos los dataframes seleccionados, sus metricas, columnas y analisis.\n",
    "#DatasetA = pd.read_csv('../Data/DatasetA.csv')\n",
    "#df = pd.DataFrame(DatasetA.data, columns=DatasetA.feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5736c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bcce9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ed58bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64670f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos parámetros globales para matplotlib.\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c86f396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploteamos puntos con Pandas\n",
    "df.plot(kind='scatter', x='temp', y='total', alpha=0.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba6c2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste con Seaborn (modelo lineal) \n",
    "sns.lmplot(x='temp', y='total', data=df, aspect=1.45,\\\n",
    "                                scatter_kws={'alpha':0.2});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d0ff4c",
   "metadata": {},
   "source": [
    "#### Analisis del dfB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de52edf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e38d39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Analisis del dfC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344b0c05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "413c301c",
   "metadata": {},
   "source": [
    "### Proximos pasos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a7a461",
   "metadata": {},
   "source": [
    "##### Se definió entrenar los modelos con el dfX por causa de XXXXX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1960e80",
   "metadata": {},
   "source": [
    "#### Modelos 1.2.2 <a class=\"anchor\" id=\"Modelos_1_2_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979207f8",
   "metadata": {},
   "source": [
    "#### Regresión lineal múltiple y con regularización dfX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202d6744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos el modelo usando solamente las variables cuantitativas y dummmies\n",
    "\n",
    "X = dfX[['XX', 'XX']]\n",
    "y = dfX['XX']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=10)\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "\n",
    "model_1 = lm.fit(X_train, y_train)\n",
    "\n",
    "print('Score model_1:', model_1.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb8796c",
   "metadata": {},
   "source": [
    "#### Regresión lineal múltiple con regularizacion dfX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c712ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos el modelo usando solamente las variables cuantitativas aplicando regularización\n",
    "lm_ridge = linear_model.RidgeCV(alphas=[0.1, 1, 10], normalize=True) \n",
    "# Definimos el rango de de búsqueda del hiperparametro explicitamente\n",
    "\n",
    "model_2 = lm_ridge.fit(X_train, y_train)\n",
    "\n",
    "print('Score model_2:', model_2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bb1c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora entrenamos el modelo con todas las variables con MCO:\n",
    "\n",
    "X_all = df.drop(['sx', 'rk', 'dg', 'sl'], axis=1) \n",
    "\n",
    "X_all_train, X_all_test, y_all_train, y_all_test = train_test_split(X_all, y, test_size=0.35, random_state=10)\n",
    "\n",
    "model_3 = lm.fit(X_all_train, y_all_train)\n",
    "\n",
    "print('Score model_3:', model_3.score(X_all_test, y_all_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b215e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora entrenamos el modelo con todas las variables con Ridge:\n",
    "\n",
    "lm_ridge = linear_model.RidgeCV(alphas=[0.00001, 0.00005, 0.0001, 0.0005, 0.001, 0.005, 0.01,\\\n",
    "                                        0.05, 0.1, 1, 5, 10],\\\n",
    "                                        normalize=True, cv=3) \n",
    "# Definimos el rango de de búsqueda del hiperparametro explicitamente\n",
    "\n",
    "model_4 = lm_ridge.fit(X_all_train, y_all_train)\n",
    "\n",
    "print('Score model_4:', model_4.score(X_all_test, y_all_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444c739d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "lm_ridge.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a004f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora entrenamos el modelo con todas las variables con Lasso:\n",
    "\n",
    "lm_lasso = linear_model.LassoCV(alphas=[0.00001, 0.00005, 0.0001, 0.0005, 0.001, 0.005, 0.01,\\\n",
    "                                        0.05, 0.1, 1, 5, 10, 15, 25],\\\n",
    "                                        normalize=True, cv=3)\n",
    "\n",
    "model_5 = lm_lasso.fit(X_all_train, y_all_train)\n",
    "\n",
    "print('Score model_5:', model_5.score(X_all_test, y_all_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dhdsblend2021] *",
   "language": "python",
   "name": "conda-env-dhdsblend2021-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
